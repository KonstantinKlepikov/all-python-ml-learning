{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext import data \n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ тональности текста\n",
    "\n",
    "датасет [sentiment140](http://help.sentiment140.com/for-students). Используем training.1600000.processed.noemoticon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF = pd.read_csv(\"input/training.1600000.processed.noemoticon.csv\", engine=\"python\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF[\"sentiment_cat\"] = tweetsDF[0].astype('category')\n",
    "tweetsDF[\"sentiment\"] = tweetsDF[\"sentiment_cat\"].cat.codes\n",
    "tweetsDF.to_csv(\"output/train-processed.csv\", header=None, index=None)      \n",
    "tweetsDF.sample(10000).to_csv(\"output/train-processed-sample.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>sentiment_cat</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5 sentiment_cat  sentiment  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...             0          0  \n",
       "1  is upset that he can't update his Facebook by ...             0          0  \n",
       "2  @Kenichan I dived many times for the ball. Man...             0          0  \n",
       "3    my whole body feels itchy and like its on fire              0          0  \n",
       "4  @nationwideclass no, it's not behaving at all....             0          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchtext генерирует набор данных из json/csv с определенными типами параметров полей. [Подробнее тут](https://torchtext.readthedocs.io/en/latest/data.html#field)\n",
    "\n",
    "Нас интересуют только маркировки и текст твитов. Остальные поля мы дропнем. Метку определим как нетекстовое поле. Текст токенизируем с помощью spaCy и переведем в нижний регистр\n",
    "\n",
    "**Чтобы работать с английским текстом в spacy** потребуетсякачнуть локаль\n",
    "\n",
    "```\n",
    "python -m spacy download en\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = data.LabelField()\n",
    "TWEET = data.Field(tokenize='spacy', lower=True)\n",
    "\n",
    "fields = [('score',None), ('id',None),('date',None),('query',None),\n",
    "          ('name',None),\n",
    "          ('tweet', TWEET),('category',None),('label',LABEL)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи TabularDataset применим определение полей к нашим данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterDataset = torchtext.data.TabularDataset(\n",
    "    path=\"output/train-processed-sample.csv\",\n",
    "    format=\"CSV\", \n",
    "    fields=fields,\n",
    "    skip_header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посплитим на трейн, валид, тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "train, test, valid = twitterDataset.split(\n",
    "    split_ratio=[0.6,0.2,0.2],\n",
    "    stratified=True, \n",
    "    strata_field='label'\n",
    ")\n",
    "\n",
    "print(len(train), len(test), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': ['loves', 'clean', ',', 'fresh', 'smelling', 'sheets'], 'label': '1'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train.examples[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение словаря\n",
    "\n",
    "с помощью методв build_vocab с параметром max_size создаем словарь, ограничив его наиболее обзщеупотребительными (например 20тыс.) Torchtext добавить еще два токена <unk> для неизвестных слов и <pad> токен отступа, который будет использоваться для подгонки всего текста до одного размера, чтобы обеспечить пакетирование в pytorch. Можно задать и другие доп.токены, но они не включены по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "TWEET.build_vocab(train, max_size = vocab_size)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13471"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TWEET.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 3798),\n",
       " ('!', 3221),\n",
       " ('.', 3128),\n",
       " (' ', 2187),\n",
       " ('to', 2097),\n",
       " ('the', 1960),\n",
       " (',', 1878),\n",
       " ('a', 1471),\n",
       " ('my', 1208),\n",
       " ('you', 1124)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TWEET.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец создадим загрузчик с помощью BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_size = 32,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.tweet),\n",
    "    sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели\n",
    "\n",
    "В первом слое создаем эмбеддинги - 300-мерный векторы. Затем следует LSTM со 100 скрытыми слоями. На выходе полносвязный слой с тремя классами (отрицательный, положительный или нейтральный твит)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurFirstLSTM(\n",
       "  (embedding): Embedding(20002, 300)\n",
       "  (encoder): LSTM(300, 100)\n",
       "  (predictor): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OurFirstLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
    "        super(OurFirstLSTM, self).__init__()\n",
    "    \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=embedding_dim,  \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=1\n",
    "        )\n",
    "        self.predictor = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        output, (hidden,_) = self.encoder(self.embedding(seq))\n",
    "        preds = self.predictor(hidden.squeeze(0))\n",
    "        return preds\n",
    "\n",
    "model = OurFirstLSTM(100,300, 20002)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Тут потребуется ссылаться на batch.tweet и batch.label, чтобы получить конкретные поля, которые нас интересуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epochs, model, optimizer, criterion, train_iterator, valid_iterator):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "     \n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch.tweet)\n",
    "            loss = criterion(predict,batch.label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * batch.tweet.size(0)\n",
    "        training_loss /= len(train_iterator)\n",
    " \n",
    "        \n",
    "        model.eval()\n",
    "        for batch_idx,batch in enumerate(valid_iterator):\n",
    "            predict = model(batch.tweet)\n",
    "            loss = criterion(predict,batch.label)\n",
    "            valid_loss += loss.data.item() * batch.tweet.size(0)\n",
    " \n",
    "        valid_loss /= len(valid_iterator)\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 24.67, Validation Loss: 13.07\n",
      "Epoch: 2, Training Loss: 22.42, Validation Loss: 12.81\n",
      "Epoch: 3, Training Loss: 20.89, Validation Loss: 14.97\n",
      "Epoch: 4, Training Loss: 19.48, Validation Loss: 13.68\n",
      "Epoch: 5, Training Loss: 18.29, Validation Loss: 14.14\n",
      "Epoch: 6, Training Loss: 19.32, Validation Loss: 15.57\n",
      "Epoch: 7, Training Loss: 19.93, Validation Loss: 14.05\n",
      "Epoch: 8, Training Loss: 19.67, Validation Loss: 14.98\n",
      "Epoch: 9, Training Loss: 19.12, Validation Loss: 16.36\n",
      "Epoch: 10, Training Loss: 18.85, Validation Loss: 15.11\n"
     ]
    }
   ],
   "source": [
    "train(10, model, optimizer, criterion, train_iterator, valid_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказания\n",
    "\n",
    "Недостаток torchtext - его сложно заставить делать предикшены. В нашем случае мы эмулируем конвеер обработки и делаем прогноз на выходе.\n",
    "\n",
    "В этой функции мы вызываем preprocess() , который делает токенизацию на основе SpaCy. Затем process() делает из токенов тензор, основываясь на построенном словаре (Torchtext ожидает пакет строк, поэтому необходимо передавать данные в функцию в виде списка спиосков). Затем мы отдаем все это в модель и создаем тензор, на сонове которого делаем предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tweet(tweet):\n",
    "    categories = {0: \"Negative\", 1:\"Positive\"}\n",
    "    processed = TWEET.process([TWEET.preprocess(tweet)])\n",
    "    processed = processed.to(device)\n",
    "    return categories[model(processed).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
