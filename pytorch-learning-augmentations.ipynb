{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея микслоадера заключается в миксовании изображений из разных классов в определенном процентном сотношщении. Тогда выходом модели было бы не приближение определенных классов к 1 или 0, а балансировка между классами. Это позволяет улучшить обобщающую способность. \n",
    "\n",
    "Для реализации метода нужна спец.функция потерь смешанного изображения:\n",
    "\n",
    "$$p * loss(image1) + (1-p) * loss(image2)$$\n",
    "\n",
    ", где p - это доля первого изображения на смешанном. p лучше всего выбрать из бета-распределения - при таком распределении большинство смешанных изображений в сете будет либо тем либо другим.\n",
    "\n",
    "В коде у нас появляется два загрузчика данных, что потенциально влечет ошибку, т.к. пакеты не сбалансированы. Это решается случайным перемещением входящего пакета. Это все равно влечет за собой корллизию, так как можно получить смешанное изображение1 и изображение2 с бетапараметром 0,3, а следом в той же партии смешать эти же изображения с параметром 0,7. Чтобы этого не случалось можно реализовать смесь так, что неперемешанная партия всегда будет иметь наивысший компонент (в fast.ai это реализовано через mix_parameters = torch.max(mix_parameters, 1 - mix_parameters)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим микслоадер\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, mix_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in zip(train_loader, mix_loader):\n",
    "            ((inputs, targets), (inputs_mix, targets_mix)) = batch\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            inputs_mix = inputs_mix.to(device)\n",
    "            targets_mix = targets_mix.to(device)\n",
    "            # вариант со случайным перемещением пакета\n",
    "            # shuffle = torch.randperm(inputs.size(0))\n",
    "            # inputs_mix = inputs[shuffle]\n",
    "            # targets_mix = targets[shuffle]\n",
    "            \n",
    "            distribution = torch.distribution.beta.Beta(0.5, 0.5)\n",
    "            beta = distribution.expand(torch.zeros(batch_size).shape).sample().to(device)\n",
    "            \n",
    "            # преобразуем бету в размерност ьвходного тензора [batch_size, channels, height, width]\n",
    "            mixup = beta[:, None, None, None]\n",
    "            \n",
    "            inputs_mixed = mixup * inputs + (1 - mixup) * inputs_mix            \n",
    "            targets_mixed = beta * targets + (1 - beta) * inputs_mix            \n",
    "            output_mixed = model(inputs_mixed)\n",
    "            \n",
    "            # среднее двух смешанных потерь\n",
    "            loss = (loss_fn(output, targets) * beta + loss_fn(output, targets_mixed) * (1 - beta)).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))\n",
    "        \n",
    "def find_lr(model, loss_fn, optimizer, train_loader, init_value=1e-8, final_value=10.0, device=\"cpu\"):\n",
    "    number_in_epoch = len(train_loader) - 1\n",
    "    update_step = (final_value / init_value) ** (1 / number_in_epoch)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0][\"lr\"] = lr\n",
    "    best_loss = 0.0\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in train_loader:\n",
    "        batch_num += 1\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Crash out if loss explodes\n",
    "\n",
    "        if batch_num > 1 and loss > 4 * best_loss:\n",
    "            if(len(log_lrs) > 20):\n",
    "                return log_lrs[10:-5], losses[10:-5]\n",
    "            else:\n",
    "                return log_lrs, losses\n",
    "\n",
    "        # Record the best loss\n",
    "\n",
    "        if loss < best_loss or batch_num == 1:\n",
    "            best_loss = loss\n",
    "\n",
    "        # Store the values\n",
    "        losses.append(loss.item())\n",
    "        log_lrs.append((lr))\n",
    "\n",
    "        # Do the backward pass and optimize\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the lr for the next step and store\n",
    "\n",
    "        lr *= update_step\n",
    "        optimizer.param_groups[0][\"lr\"] = lr\n",
    "    if(len(log_lrs) > 20):\n",
    "        return log_lrs[10:-5], losses[10:-5]\n",
    "    else:\n",
    "        return log_lrs, losses  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сглаживание меток\n",
    "\n",
    "При прогнозе мы задаем определенный зазор e (эписилон), который вычитаем из значения вероятности класса. Для этиого нам надо только обернуть функцию потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, epsilon=0.1):\n",
    "        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        num_classes = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = (-log_preds.sum(dim=-1)).mean()\n",
    "        nll = F.nll_loss(log_preds, target)\n",
    "        final_loss = self.epsilon * loss / num_classes + (1 - self.epsilon) * nll\n",
    "        \n",
    "        return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
